# ProjectPythonMICHALSKI-Laurent


Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico

Cleaning and starting observations:
With the presentation of the dataset , we have all the attribut with a survey to know the relativity of the question ask, not to only ask the computer but also your reflexion as a human
-In First,we question this survey and the fact that 77% of the data is generated by a computer.
-In Second ,we do a basic manipulation of the dataset by looking to the correlation and swarmplot of seaborn to look to MTRANS and some other categoricals attribut
-In Third, we question the cleaning and changing that need to be done , first there is no none value, second the value generated by the computer have float value with a lot of decimal that can impact the visualization , we round everythings that need to , at last how we can change the quality values . First we change , the binary attribut like yes/no and Male/Female in 1/0 ,after we do a pourcentage approche with the no/sometimes/Always like quality  attribut and finaly with MTRANS we choose to create a new attribut in combinaison with FAF, to discribe a new attribut that concerne the time spend to physical activity in relation with the 30min/day physical walking/activity that allow to increase the healthiness of people.

Modelling the data, classification was choose as modeling because it a supervized dataset with label :
-By using the new numerical data with the only quality parameter NObeyesdad that corrolate with the IMC value, we choice first a basic model Kneighborns , after we go on some binomial model like DecisionTree , then Boost to finally go to RandomForest with 100 estimators that give 0.96 score .
Finaly to enchant the view of the basic plot , we choose to use a heatmap to represent the concentration of the different prediction that by passing to arrange the prediction with the Y_train , to have a way to have a matrix to do a heatmap.

Data Visualization:
-We needed to give more meaning to the data that we have , the heatmap was a solution , but the principal conclusion was the 77% creation of the data by the computer impact the analyze a lot, as the frequency of some variable drop a lot (if we think that the first 458 data lines where the survey ones). A lot of variable have absolute dominance in the choice of the people like the people who SMOKE or the people with ancestor in their family who as overweight . There create inconsistence that we look with the logic of the human look to decide if they same pertinent or not.

No API Django/Flask
